{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333acb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import train\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random,yaml\n",
    "import functools\n",
    "import pathlib,os,sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7620591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make all paths relative\n",
    "base_path = pathlib.Path().absolute()\n",
    "\n",
    "# Importing configurations\n",
    "yml_path = f\"{base_path}/config/config.yml\"\n",
    "with open(yml_path, \"r\") as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "model_name = cfg[\"params\"][\"model_name\"]\n",
    "\n",
    "# Loading model and pretrained weights\n",
    "print(\"Loading model and weights...\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "checkpoint = torch.load(f\"{base_path}/weights/best_model.pth\")\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "model.to('cpu')\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051725a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    '''\n",
    "    Function: converts words to tokens.\n",
    "    Input: Word\n",
    "    Output: tokens, attention-mask\n",
    "    '''\n",
    "    res = tokenizer.encode_plus(text, padding=\"max_length\")\n",
    "    return torch.tensor(res.input_ids), torch.tensor(res.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bae378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence, model):\n",
    "    '''\n",
    "    Function: Prediction\n",
    "    Input: sentence, model\n",
    "    Output: NIL\n",
    "    '''\n",
    "    inp_ids, inp_mask = tokenize(sentence)\n",
    "    inp_ids = inp_ids.unsqueeze(0)\n",
    "    inp_ids = inp_ids.to('cpu')\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids = inp_ids)\n",
    "    print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type the sentence to be processed.\n",
    "sentence = \"Dog barks at the cat.\"\n",
    "predict(sentence, model)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "adaquant",
   "language": "python",
   "name": "adaquant"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
